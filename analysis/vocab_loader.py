"""Vocabulary loader — loads all word lists from data/vocab/{lang}.json.

Every module that needs word lists (greetings, trivials, currency words,
compliance phrases, prohibited phrases, etc.) loads them through this module.

Vocab files are generated by scripts/build_vocab.py from HuggingFace datasets.
If vocab files don't exist, returns empty sets/dicts (graceful degradation).
"""

import json
from pathlib import Path
from loguru import logger

_VOCAB_DIR = Path("data/vocab")
_cache: dict[str, dict] = {}


def _load_vocab(lang: str) -> dict:
    """Load vocabulary for a language, with caching."""
    if lang in _cache:
        return _cache[lang]

    vocab_path = _VOCAB_DIR / f"{lang}.json"
    if not vocab_path.exists():
        logger.debug(f"No vocab file for '{lang}' at {vocab_path}")
        _cache[lang] = {}
        return {}

    try:
        with open(vocab_path) as f:
            data = json.load(f)
        _cache[lang] = data
        logger.info(f"Loaded vocab for '{lang}' ({len(data)} categories)")
        return data
    except Exception as e:
        logger.warning(f"Failed to load vocab for '{lang}': {e}")
        _cache[lang] = {}
        return {}


def get_greetings(lang: str = "en") -> set[str]:
    """Get greeting phrases for a language."""
    vocab = _load_vocab(lang)
    return set(vocab.get("greetings", []))


def get_trivial_phrases(lang: str = "en") -> set[str]:
    """Get trivial/acknowledgment phrases for a language."""
    vocab = _load_vocab(lang)
    return set(vocab.get("trivial_phrases", []))


def get_currency_words(lang: str = "en") -> list[dict]:
    """Get currency word patterns for a language.

    Returns list of dicts: [{"words": ["rupees", "rs"], "currency": "INR"}, ...]
    """
    vocab = _load_vocab(lang)
    return vocab.get("currency_words", [])


def get_date_words(lang: str = "en") -> dict:
    """Get date-related words for a language.

    Returns: {"months": ["January", ...], "relative": ["tomorrow", ...], "days": ["Monday", ...]}
    """
    vocab = _load_vocab(lang)
    return vocab.get("date_words", {})


def get_compliance_keywords(lang: str = "en") -> dict:
    """Get compliance disclosure keywords for a language.

    Returns dict keyed by call_type, each containing list of disclosure checks
    with their keywords.
    """
    vocab = _load_vocab(lang)
    return vocab.get("compliance_keywords", {})


def get_prohibited_phrases(lang: str = "en") -> dict[str, list[str]]:
    """Get prohibited phrases by category for a language.

    Returns: {"threats": [...], "coercion": [...], "misleading": [...], ...}
    """
    vocab = _load_vocab(lang)
    return vocab.get("prohibited_phrases", {})


def get_end_call_phrases(lang: str = "en") -> list[str]:
    """Get phrases indicating customer wants to end the call."""
    vocab = _load_vocab(lang)
    return vocab.get("end_call_phrases", [])


def get_financial_terms(lang: str = "en") -> dict:
    """Get financial term patterns for a language.

    Returns: {"corrections": {"emmy": "EMI", ...}, "acronyms": ["EMI", "KYC", ...]}
    """
    vocab = _load_vocab(lang)
    return vocab.get("financial_terms", {})


def get_fraud_indicators() -> dict:
    """Get fraud/scam indicator phrases extracted from HuggingFace datasets.

    Returns dict with categories:
    - remote_access_tools: phrases requesting remote desktop tools
    - urgency_pressure: time pressure / urgency language
    - credential_requests: requests for passwords, PINs, OTPs
    - authority_impersonation: impersonating government/law enforcement
    - vague_identity: non-specific organizational identity
    - financial_threats: threats of arrest, legal action, etc.
    - social_engineering: trust-building manipulation phrases
    - scam_type_keywords: per-scam-type keyword sets
    """
    fraud_path = _VOCAB_DIR / "fraud_indicators.json"
    if "fraud" in _cache:
        return _cache["fraud"]

    if not fraud_path.exists():
        logger.debug("No fraud indicators file — run scripts/build_vocab.py")
        _cache["fraud"] = {}
        return {}

    try:
        with open(fraud_path) as f:
            data = json.load(f)
        _cache["fraud"] = data
        total = sum(len(v) for v in data.values() if isinstance(v, list) and v and isinstance(v[0], str))
        logger.info(f"Loaded {total} fraud indicator phrases")
        return data
    except Exception as e:
        logger.warning(f"Failed to load fraud indicators: {e}")
        _cache["fraud"] = {}
        return {}


def has_vocab(lang: str) -> bool:
    """Check if vocabulary exists for a language."""
    return (_VOCAB_DIR / f"{lang}.json").exists()


def clear_cache():
    """Clear the vocabulary cache (useful for testing)."""
    _cache.clear()
